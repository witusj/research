{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: '2024-06-30'\n",
        "author: Witek ten Hove\n",
        "format:\n",
        "  html:\n",
        "    css: styles.css\n",
        "    html-math-method: katex\n",
        "    include-in-header:\n",
        "      - scripts.html\n",
        "bibliography: bibliography.bib\n",
        "editor:\n",
        "  markdown:\n",
        "    wrap: sentence\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OBP:\n",
        "\n",
        "Afspraken:\n",
        "\n",
        "-   [ ] We gaan verder kijken naar XG Boosting\n",
        "-   [ ] Data: optimale schedules, labels: waiting times en tardiness\n",
        "\n",
        "NB:\n",
        "\n",
        "-   Wat wordt de workflow van de online tool?\n",
        "\n",
        "-   Welke onderdelen van de workflow kunnen parallel worden uitgevoerd?\n",
        "\n",
        "-   Idee Joost: cardinal analysis - is schedule A better than B?\n",
        "    -\\> Yes/No\n",
        "\n",
        "-   Idee Witek: Als een model is getraind op een set schedules met lengte T en de output is de reeks wachttijden voor ieder interval, dan kan ook iedere schedule met een lengte korter dan T met hetzelfde model worden bepaald.\n",
        "    Stel het model is getraind op T = 7. Dan kan iedere schedule T = 5 ook direct worden ingevoerd als $[x_0, x_1, x_2, x_3, x_4, 0, 0]$. Sterker nog: met $x_5 = 1$ wordt in dit geval overwerk ook berekend.\n",
        "    \n",
        "![Notities overleg 04-07-2024](images/notes.jpeg)\n",
        "\n",
        "## Experiment: Application of ML models to calculate loss values\n",
        "\n",
        "In this experiment we will try out several Machine Learning models to predict the outcome of a loss function from a given schedule with $T$ intervals of length $d$.\n",
        "A schedule with $N$ patients can be defined as a vector\n",
        "\n",
        "$$\n",
        "x = (x_1, x_2, \\ldots, x_T) \\in \\mathbb{N}_0^T\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{ such that } \\sum_{t=1}^{T} x_t = N.\n",
        "$$\n",
        "\n",
        "Waiting times are calculated using a Lindley recursion:\n",
        "\n",
        "$$\n",
        "W_{1, t} = \\max(0, W_{1, t-1} + V_{t-1} - d)\n",
        "$$\n",
        "\n",
        "$$\n",
        "W_{n, t} = W_{1,t} * S^{(n-1)}\n",
        "$$\n",
        "\n",
        "where $W_{n, t}$ is the waiting time distribution of patient $n$ in interval $t$, $V_{T}$ is the distribution of the total amount of work in the last interval, $S^{(k)}$ is the k-fold convolution of the service time distribution $S$ and $W*S$ is the convolution of the waiting time distribtion $W$ with $S$.\n",
        "\n",
        "We are interested in calculating for each schedule $x$ the expected total waiting time and overtime\n",
        "\n",
        "$$\n",
        "E(W(x)) = \\sum_{t=1}^{T} \\sum_{n=1}^{x_t} E(W_{n, t})\n",
        "$$\n",
        "\n",
        "$$\n",
        "E(L(x)) = E(\\max(0, W_{1, T} + V_{T} - d)),\n",
        "$$\n",
        "\n",
        "The loss function is a weighted average of expected waiting time and overtime\n",
        "\n",
        "$$\n",
        "C(x) = \\alpha_W E(W(x)) + \\alpha_L E(L(x))\n",
        "$$\n",
        "\n",
        "Directly mapping schedules to loss values would significantly reduce the practical applicability of our method.\n",
        "The weights in the loss function are subjective values that reflect the perceived relative importance of their corresponding factors.\n",
        "Consequently, each time the weights are adjusted, the model would need to be retrained.\n",
        "\n",
        "A more effective approach would be to train separate models for each factor in the loss function.\n",
        "Once we predict the levels of each factor, we can input them into the loss function using the desired weights.\n",
        "In this experiment we will even go a step further and try to predict the expected waiting times in each interval instead of the aggregated values for the whole schedule.\n",
        "\n",
        "## Setup\n",
        "\n",
        "Load all packages, the schedule class and selected functions.\n",
        "\n",
        "::: callout-warning\n",
        "This code chunk contains an important variable `run_flag`.\n",
        "If it's set to False, some code further in the notebook will not run.\n",
        "You can use this to save on execution times when making minor changes.\n",
        ":::"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from schedule_class import NewSchedule, generate_schedules, service_time_with_no_shows\n",
        "from functions import generate_all_schedules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import hashlib\n",
        "import time\n",
        "\n",
        "def compute_hash(lst):\n",
        "    \"\"\"\n",
        "    Compute a hash for a given list of items.\n",
        "    \"\"\"\n",
        "    hasher = hashlib.md5()\n",
        "    for item in lst:\n",
        "        # Convert each item to a string and then encode it to bytes\n",
        "        hasher.update(str(item).encode('utf-8'))\n",
        "    return hasher.hexdigest()\n",
        "\n",
        "def save_hash(hash_value, hash_file):\n",
        "    with open(hash_file, 'w') as f:\n",
        "        f.write(hash_value)\n",
        "        \n",
        "def load_hash(hash_file):\n",
        "    try:\n",
        "        with open(hash_file, 'r') as f:\n",
        "            return f.read().strip()\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "\n",
        "hash_file = 'data_hash.txt'\n",
        "saved_hash = load_hash(hash_file)\n",
        "run_flag = True # Switch to run highly intensive code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runner functions for creating and running a schedule instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def run_schedule(x, d, s, q, omega, print_system=True):\n",
        "    schedule = NewSchedule(x=x, d=d, s=s, q=q, omega=omega)\n",
        "    schedule.calculate_system_states(until=len(x))\n",
        "    schedule.calculate_wait_times()\n",
        "    schedule.calculate_loss()\n",
        "    if(print_system): print(schedule)\n",
        "    return(schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate dataset\n",
        "\n",
        "Generate a dataset for training and testing of various schedules of lenght $T = 10$ with $N \\in \\{1, \\dots, 14\\}$ and corresponding aggregated expected waiting times in each interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "max_N = 10\n",
        "T =  7\n",
        "d = 3\n",
        "s = [0.0, 0.27, 0.28, 0.2, 0.15, 0.1]\n",
        "indices = np.arange(len(s))\n",
        "exp_s = (indices * s).sum()\n",
        "q = 0.2\n",
        "s_adj = service_time_with_no_shows(s, q)\n",
        "indices = np.arange(len(s_adj))\n",
        "exp_s_adj = (indices * s_adj).sum()\n",
        "print(f'service time distribution with no-shows: {s_adj} with expcted value: {exp_s_adj}')\n",
        "omega = 0.5\n",
        "\n",
        "list_to_hash = [max_N, d, s, q, omega]\n",
        "hashed_list = compute_hash(list_to_hash)\n",
        "if(hashed_list != saved_hash):\n",
        "  run_flag = True\n",
        "  save_hash(hashed_list, hash_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if(run_flag):\n",
        "  # Start timing\n",
        "  start_time = time.time()\n",
        "  \n",
        "  samples_names = [f'x_{t}' for t in range(T)]\n",
        "  samples = pd.DataFrame(columns = samples_names)\n",
        "  labels_names = [f'ew_{t}' for t in range(T)]\n",
        "  labels = pd.DataFrame(columns = labels_names)\n",
        "  \n",
        "  for n in range(1, max_N+1):\n",
        "      schedules = generate_all_schedules(n, T) # Generates all possible schedules with length T\n",
        "      print(f'N = {n}, # of schedules = {len(schedules)}')\n",
        "      for schedule in schedules:\n",
        "        x = np.array(schedule, dtype=np.int64)\n",
        "        sch = run_schedule(x, d, s, q, omega, False)\n",
        "        \n",
        "        # Convert the current data dictionary to a DataFrame and append it to the main DataFrame\n",
        "        temp_samples = pd.DataFrame([x], columns=samples_names)\n",
        "        samples = pd.concat([samples, temp_samples], ignore_index=True)\n",
        "        temp_labels = pd.DataFrame([sch.system['ew']], columns=labels_names)\n",
        "        labels = pd.concat([labels, temp_labels], ignore_index=True)\n",
        "  \n",
        "  samples = samples.astype(np.int64)\n",
        "  labels = labels.astype(np.float64)\n",
        "  print(f'samples: {samples.tail()}\\nlabels: {labels.tail()}')\n",
        "  \n",
        "  # End timing\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nExecution time: {elapsed_time:.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost\n",
        "\n",
        "::: panel-tabset\n",
        "## Modeling\n",
        "\n",
        "### Create workflow\n",
        "\n",
        "![CRISP DM Workflow](https://upload.wikimedia.org/wikipedia/commons/b/b9/CRISP-DM_Process_Diagram.png){width=\"600\"}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def xgboost_workflow(X, y):\n",
        "  # Start timing\n",
        "  start_time = time.time()\n",
        "  \n",
        "  # Data preparation: create training and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "  # Train models\n",
        "  params = {\n",
        "      'objective': 'reg:squarederror',\n",
        "      'max_depth': 3,\n",
        "      'eta': 0.1,\n",
        "      'verbosity': 2\n",
        "  }\n",
        "  num_round = 100\n",
        "  # Model\n",
        "  dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "  dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "  model = xgb.train(params, dtrain, num_round)\n",
        "  # Make predictions\n",
        "  preds = model.predict(dtest)\n",
        "  # Evaluate\n",
        "  mse = mean_squared_error(y_test, preds)\n",
        "  # End timing\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nExecution time: {elapsed_time:.2f} seconds\")\n",
        "  return(y_test, preds, mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run XGBoost workflow\n",
        "\n",
        "For each of the total expected waiting time per interval we want to train an XGBoost model.\n",
        "As input we take the schedule upto the current interval:\n",
        "\n",
        "$$\n",
        "\\text{from } x_{0, \\dots, t} \\text{ predict } \\sum_{n=1}^{x_t} E(W_{n, t})\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = samples\n",
        "y = labels\n",
        "if(run_flag):\n",
        "  # Start timing\n",
        "  start_time = time.time()\n",
        "\n",
        "  results_names = ['interval', 'actual', 'predicted']\n",
        "  results = pd.DataFrame(columns = results_names)\n",
        "  mse_list = []\n",
        "  for t in range(1, T+1):\n",
        "      X_subset = X.iloc[:, :t]\n",
        "      y_subset = y.iloc[:, t-1]\n",
        "      y_test, preds, mse = xgboost_workflow(X_subset, y_subset)\n",
        "      temp_results = pd.DataFrame({\n",
        "        'interval': [t-1] * len(y_test),\n",
        "        'actual': y_test,\n",
        "        'predicted': preds\n",
        "        })\n",
        "      results = pd.concat([results, temp_results], ignore_index=True)\n",
        "      mse_list.append(mse)\n",
        "      \n",
        "      print(f\"Interval {t-1}, MSE: {mse}\")\n",
        "      \n",
        "  print(f'\\n{results.head()}\\n...\\n{results.tail()}')\n",
        "  \n",
        "  # End timing\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nExecution time: {elapsed_time:.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n",
        "\n",
        "::: column-screen-inset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the number of rows and columns for the subplot grid\n",
        "rows = (T + 2) // 3  # Number of rows, adjust based on the total number of plots (adding 2 to ensure we have enough rows)\n",
        "cols = 3  # Number of columns\n",
        "\n",
        "# Create a subplot figure\n",
        "fig = make_subplots(rows=rows, cols=cols, subplot_titles=[f'Interval {t}' for t in range(T)])\n",
        "\n",
        "def add_jitter(values, jitter_amount=0.0):\n",
        "    return values + np.random.uniform(-jitter_amount, jitter_amount, len(values))\n",
        "\n",
        "for t in range(T):\n",
        "    comparison_df = results[results['interval'] == t]\n",
        "    # Add jitter to actual and predicted values\n",
        "    jittered_actual = add_jitter(comparison_df['actual'])\n",
        "    jittered_predicted = add_jitter(comparison_df['predicted'])\n",
        "    \n",
        "    # Get the row and column index for the current plot\n",
        "    row = (t // cols) + 1\n",
        "    col = (t % cols) + 1\n",
        "    \n",
        "    # Add the scatter plot with jittered points to the subplot figure\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=jittered_actual, y=jittered_predicted, mode='markers', name=f'Interval {t}', showlegend=False),\n",
        "        row=row, col=col\n",
        "    )\n",
        "    \n",
        "    # Round the MSE value to two decimals\n",
        "    rounded_mse = round(mse_list[t], 2)\n",
        "    \n",
        "    # Update subplot title with MSE\n",
        "    fig.layout.annotations[t].text = f'Interval {t}</br></br><sub>MSE = {rounded_mse}, # Samples = {len(comparison_df[\"actual\"])}</sub>'\n",
        "\n",
        "# Update the layout of the subplot figure\n",
        "fig.update_layout(\n",
        "    height=1000,  # Adjust height as needed\n",
        "    width=1200,  # Adjust width as needed\n",
        "    title_text=\"XGBoost: Actual vs Predicted Waiting Times Across Intervals\",\n",
        "    title={\n",
        "        'y': 0.95,  # Position the title closer to the top\n",
        "        'x': 0.5,  # Center the title\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'\n",
        "    },\n",
        "    margin=dict(l=150, r=20, t=180, b=100)  # Add top margin to create space between title and plots\n",
        ")\n",
        "\n",
        "# Add shared axis labels\n",
        "fig.add_annotation(dict(font=dict(size=16),\n",
        "                        x=0.5,\n",
        "                        y=-0.1,\n",
        "                        showarrow=False,\n",
        "                        text=\"Actual\",\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "fig.add_annotation(dict(font=dict(size=16),\n",
        "                        x=-0.1,\n",
        "                        y=0.5,\n",
        "                        showarrow=False,\n",
        "                        text=\"Predicted\",\n",
        "                        textangle=-90,\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "# Print the grid layout to debug the row and column index\n",
        "fig.print_grid()\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "## Model explanation\n",
        "\n",
        "1.  **Function Definition**:\n",
        "    -   The function `xgboost_workflow` takes two arguments: `X` (the feature set) and `y` (the target variable).\n",
        "2.  **Data Preparation**:\n",
        "    -   The function splits the data into training and testing sets using `train_test_split` from the `sklearn.model_selection` module.\n",
        "    -   `X_train` and `X_test` are the training and testing subsets of the feature set, respectively.\n",
        "    -   `y_train` and `y_test` are the corresponding subsets of the target variable.\n",
        "    -   The `test_size` parameter is set to 0.2, meaning 20% of the data is used for testing, and 80% for training.\n",
        "    -   The `random_state` parameter ensures reproducibility by seeding the random number generator.\n",
        "3.  **Model Training Parameters**:\n",
        "    -   A dictionary `params` is defined to set the hyperparameters for the XGBoost model:\n",
        "        -   `'objective': 'reg:squarederror'` specifies that the objective function is regression using squared error.\n",
        "        -   `'max_depth': 3` sets the maximum depth of the trees to 3, controlling the complexity of the model.\n",
        "        -   `'eta': 0.1` sets the learning rate to 0.1, controlling the step size during optimization.\n",
        "        -   `'verbosity': 1` sets the verbosity level to 1, providing basic information about the training process.\n",
        "4.  **Number of Rounds**:\n",
        "    -   `num_round` is set to 100, indicating the number of boosting rounds (iterations) the model will undergo.\n",
        "5.  **DMatrix Creation**:\n",
        "    -   The training and testing datasets are converted into `DMatrix` objects, which are the internal data structure that XGBoost uses.\n",
        "    -   `dtrain` is the `DMatrix` for the training set, created with `X_train` and `y_train`.\n",
        "    -   `dtest` is the `DMatrix` for the testing set, created with `X_test` and `y_test`.\n",
        "6.  **Model Training**:\n",
        "    -   The XGBoost model is trained using the `xgb.train` function, which takes the parameters, the training `DMatrix`, and the number of rounds as inputs.\n",
        "    -   The trained model is returned as the output of the function.\n",
        "\n",
        "## Model options\n",
        "\n",
        "1.  **Learning Task Parameters**:\n",
        "    -   `objective`: Defines the loss function to be minimized (e.g., `reg:squarederror`, `binary:logistic`, `multi:softmax`).\n",
        "2.  **Tree Parameters**:\n",
        "    -   `max_depth`: Maximum depth of the decision trees. Larger values can lead to overfitting.\n",
        "    -   `min_child_weight`: Minimum sum of instance weight (hessian) needed in a child.\n",
        "    -   `gamma`: Minimum loss reduction required to make a further partition on a leaf node.\n",
        "3.  **Booster Parameters**:\n",
        "    -   `eta` (alias: `learning_rate`): Step size shrinkage used to prevent overfitting.\n",
        "    -   `subsample`: Proportion of training instances to use for each tree. Helps prevent overfitting.\n",
        "    -   `colsample_bytree`: Subsample ratio of columns when constructing each tree.\n",
        "    -   `lambda` (alias: `reg_lambda`): L2 regularization term on weights.\n",
        "    -   `alpha` (alias: `reg_alpha`): L1 regularization term on weights.\n",
        "4.  **Learning Task Customization**:\n",
        "    -   `scale_pos_weight`: Control the balance of positive and negative weights, useful for unbalanced classes.\n",
        "    -   `eval_metric`: Evaluation metrics to be used (e.g., `rmse`, `logloss`, `error`).\n",
        "5.  **Control Parameters**:\n",
        "    -   `n_estimators`: Number of trees to fit (number of boosting rounds).\n",
        "    -   `early_stopping_rounds`: Stop training if one metric doesnâ€™t improve after a given number of rounds.\n",
        "6.  **Tree Method Parameters**:\n",
        "    -   `tree_method`: Algorithm used to construct trees (e.g., `auto`, `exact`, `approx`, `hist`, `gpu_hist`).\n",
        "    -   `grow_policy`: Controls the growth policy for the trees. `depthwise` or `lossguide`.\n",
        "\n",
        "Adjusting these parameters allows for fine-tuning the XGBoost model to better fit the data and improve performance.\n",
        ":::\n",
        "\n",
        "## Convolutional Neural Network (CNN)\n",
        "\n",
        "::: panel-tabset\n",
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X_c = X.values\n",
        "y_c = y.values\n",
        "\n",
        "# Reshape X to have the shape (samples, height, width, channels)\n",
        "X_c = X_c.reshape((X_c.shape[0], X_c.shape[1], 1, 1))\n",
        "print(X_c.shape[0], X_c.shape[1])\n",
        "\n",
        "# Split into training and testing datasets\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.9, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build the model\n",
        "model_c = Sequential()\n",
        "model_c.add(Input(shape=(X_c.shape[1], 1, 1)))\n",
        "model_c.add(Conv2D(64, (2, 1), activation='relu'))\n",
        "model_c.add(Flatten())\n",
        "model_c.add(Dense(64, activation='relu'))\n",
        "model_c.add(Dense(y_c.shape[1]))  # Output layer with T units (one for each output value)\n",
        "\n",
        "# Compile the model\n",
        "model_c.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model_c.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if(run_flag):\n",
        "    # Start timing\n",
        "  start_time = time.time()\n",
        "  \n",
        "  model_c.fit(X_train_c, y_train_c, epochs=50, batch_size=1, verbose=2)\n",
        "  \n",
        "  # End timing\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Calculate elapsed time\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"\\nExecution time: {elapsed_time:.2f} seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Evaluate the model\n",
        "if(run_flag):\n",
        "  loss = model_c.evaluate(X_test_c, y_test_c, verbose=2)\n",
        "\n",
        "  # Make predictions\n",
        "  predictions = model_c.predict(X_test_c)\n",
        "\n",
        "  def calculate_mse(array1, array2):\n",
        "      \"\"\"\n",
        "      Calculate the Mean Squared Error between two arrays.\n",
        "  \n",
        "      Parameters:\n",
        "      array1 (np.ndarray): The first array.\n",
        "      array2 (np.ndarray): The second array.\n",
        "  \n",
        "      Returns:\n",
        "      float: The Mean Squared Error between the two arrays.\n",
        "      \"\"\"\n",
        "      # Ensure the input arrays are NumPy arrays\n",
        "      array1 = np.array(array1)\n",
        "      array2 = np.array(array2)\n",
        "      \n",
        "      # Calculate the MSE\n",
        "      mse = np.mean((array1 - array2) ** 2)\n",
        "    \n",
        "      return mse\n",
        "\n",
        "  mse_cnn = [calculate_mse(y_test_c[t], predictions[t]) for t in range(T)]\n",
        "  mse_cnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots\n",
        "\n",
        "::: column-screen-inset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the number of rows and columns for the subplot grid\n",
        "rows = (T + 2) // 3  # Number of rows, adjust based on the total number of plots (adding 2 to ensure we have enough rows)\n",
        "cols = 3  # Number of columns\n",
        "\n",
        "# Create a subplot figure\n",
        "fig = make_subplots(rows=rows, cols=cols, subplot_titles=[f'Interval {t}' for t in range(T)])\n",
        "\n",
        "for t in range(T):\n",
        "    \n",
        "    # Get the row and column index for the current plot\n",
        "    row = (t // cols) + 1\n",
        "    col = (t % cols) + 1\n",
        "    \n",
        "    # Add the scatter plot with jittered points to the subplot figure\n",
        "    fig.add_trace(\n",
        "        go.Scatter(x=y_test_c[:,t], y=predictions[:,t], mode='markers', name=f'Interval {t}', showlegend=False),\n",
        "        row=row, col=col\n",
        "    )\n",
        "    \n",
        "    # Update subplot title with MSE\n",
        "    fig.layout.annotations[t].text = f'Interval {t}</br></br><sub>MSE = {round(mse_cnn[t], 2)}, # Samples = {len(y_test_c)}</sub>'\n",
        "\n",
        "# Update the layout of the subplot figure\n",
        "fig.update_layout(\n",
        "    height=1000,  # Adjust height as needed\n",
        "    width=1200,  # Adjust width as needed\n",
        "    title_text=\"CNN: Actual vs Predicted Waiting Times Across Intervals\",\n",
        "    title={\n",
        "        'y': 0.95,  # Position the title closer to the top\n",
        "        'x': 0.5,  # Center the title\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'\n",
        "    },\n",
        "    margin=dict(l=150, r=20, t=180, b=100)  # Add top margin to create space between title and plots\n",
        ")\n",
        "\n",
        "# Add shared axis labels\n",
        "fig.add_annotation(dict(font=dict(size=16),\n",
        "                        x=0.5,\n",
        "                        y=-0.1,\n",
        "                        showarrow=False,\n",
        "                        text=\"Actual\",\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "fig.add_annotation(dict(font=dict(size=16),\n",
        "                        x=-0.1,\n",
        "                        y=0.5,\n",
        "                        showarrow=False,\n",
        "                        text=\"Predicted\",\n",
        "                        textangle=-90,\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "# Print the grid layout to debug the row and column index\n",
        "fig.print_grid()\n",
        "\n",
        "# Show the figure\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        ":::"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}