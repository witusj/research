---
title: "2024-07-18"
author: "Witek ten Hove"
format: html
editor: visual
jupyter: python3
---

Besproken met Joost:

-   Model bouwen voor pairwise ranking.
-   Performance vergelijken met cardinal ML model
-   Computation time vergelijken:
    -   Lindley recursion \<\> cardinal ML
    -   Cardinal ML model pairwise ranking vs direct pairwise ranking
-   Cardinal ML model met large objective punisment in loss function ontwikkelen

## Setup and load data

```{python}
import pickle
import random
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score
from sklearn.base import clone
from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV
```

```{python}
class ScheduleData:
  def __init__(self, N: int, T: int, samples, labels):
    self.N = N
    self.T = T
    self.samples = samples
    self.labels = labels
  
  def describe_data(self):
    print(f'N = {self.N}', f'T = {self.T}', '\nSamples',self.samples.tail(10), '\nLabels', self.labels.tail(10), sep = "\n")
  
  def create_pair_list(self, n):
    S = list(range(len(self.samples)))
    self.T = random.choices(S, k=n)
    self.P = []
    
    for t in self.T:
        # Create a list of possible choices excluding t
        possible_choices = [s for s in S if s != t]
        
        # Choose a random element from the possible choices
        p = random.choice(possible_choices)
        
        # Add the chosen element to the result list
        self.P.append(p)
    
    samples_s1 = self.samples.iloc[self.T, :].values.tolist()
    samples_s2 = self.samples.iloc[self.P, :].values.tolist()
    self.pair_list = combined_samples = list(zip(samples_s1, samples_s2))
    self.lables_s1 = self.labels.loc[self.T, 'obj'].values.tolist()
    self.lables_s2 = self.labels.loc[self.P, 'obj'].values.tolist()
    self.lables_rank = [1 * (self.lables_s1[i] > self.lables_s2[i]) for i in range(len(self.lables_s1))]
    print(self.pair_list[:15], "\n", self.lables_s1[:15], "\n", self.lables_s2[:15], "\n", self.lables_rank[:15])
    
with open('./experiments/data.pickle', 'rb') as file:
  sch_data: ScheduleData = pickle.load(file)
  
sch_data.description
sch_data.describe_data()
sch_data.create_pair_list(16000)
```

## Prepare data

```{python}
# Prepare the dataset
X = []
for pair in sch_data.pair_list:
    X.append(pair[0] + pair[1])

X = np.array(X)
y = np.array(sch_data.lables_rank)

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

## Train and evaluate model

```{python}
def fit_and_score(estimator, X_train, X_test, y_train, y_test):
    """Fit the estimator on the train set and score it on both sets"""
    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)])

    train_score = estimator.score(X_train, y_train)
    test_score = estimator.score(X_test, y_test)

    return estimator, train_score, test_score


cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)

# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
    tree_method="hist",
    max_depth=6,
    min_child_weight=1,
    gamma=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    learning_rate=0.1,
    n_estimators=100,
    early_stopping_rounds=10
)

results = []

for train_idx, test_idx in cv.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    est, train_score, test_score = fit_and_score(
        clone(clf), X_train, X_test, y_train, y_test
    )
    results.append((est, train_score, test_score))

# Print results
for i, (est, train_score, test_score) in enumerate(results):
    print(f"Fold {i+1} - Train Score: {train_score:.4f}, Test Score: {test_score:.4f}")
```

## Test

The model seems to be having trouble ranking schedules with close similarity consistently. This could indicate model overfitting. Solutions: create training sets with close pairs or add close pairs to the existing training data set.

```{python}
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
    tree_method="hist",
    max_depth=6,
    min_child_weight=1,
    gamma=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    learning_rate=0.1,
    n_estimators=100
)

clf.fit(X, y)

input_X = [
            ([9, 1, 0, 0, 0, 0, 0], [8, 2, 0, 0, 0, 0, 0]),
            ([8, 2, 0, 0, 0, 0, 0], [9, 1, 0, 0, 0, 0, 0]),
            ([3, 1, 1, 1, 0, 1, 2], [2, 1, 1, 1, 0, 1, 3]),
            ([2, 1, 1, 1, 0, 1, 3], [3, 1, 1, 1, 0, 1, 2]),
            ([3, 1, 1, 1, 0, 1, 2], [9, 1, 0, 0, 0, 0, 0]),
            ([8, 2, 0, 0, 0, 0, 0], [3, 1, 1, 1, 0, 1, 2])
            ]
X_new = []
for pair in input_X:
    X_new.append(pair[0] + pair[1])
    
# Predict the target for new data
y_pred = clf.predict(X_new)

# If you want to get the probability estimates
y_pred_proba = clf.predict_proba(X_new)

print(f"y_pred = {y_pred}, \ny_pred_proba = \n{y_pred_proba}")
```

