---
title: "2024-07-18"
author: "Witek ten Hove"
format: html
editor: visual
jupyter: python3
---

Besproken met Joost:

-   Model bouwen voor pairwise ranking.
-   Performance vergelijken met cardinal ML model
-   Computation time vergelijken:
    -   Lindley recursion \<\> cardinal ML
    -   Cardinal ML model pairwise ranking vs direct pairwise ranking
-   Cardinal ML model met large objective punisment in loss function ontwikkelen

## Setup and load data

```{python}
from schedule_class import NewSchedule, generate_schedules, service_time_with_no_shows
import pickle
import random
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV
from sklearn.metrics import mean_squared_error, make_scorer, accuracy_score
from sklearn.base import clone
from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV
from itertools import chain, combinations
```

```{python}
class ScheduleData:
  def __init__(self, N: int, T: int, samples, labels):
    self.N = N
    self.T = T
    self.samples = samples
    self.labels = labels
  
  def describe_data(self):
    print(f'N = {self.N}', f'T = {self.T}', '\nSamples',self.samples.tail(10), '\nLabels', self.labels.tail(10), sep = "\n")
  
  def create_pair_list(self, n): # Create a set of randomly selected pairs of schedules
    S = list(range(len(self.samples)))
    Q = random.choices(S, k=n)
    P = []
    
    for q in Q:
        # Create a list of possible choices excluding t
        possible_choices = [s for s in S if s != q]
        
        # Choose a random element from the possible choices
        p = random.choice(possible_choices)
        
        # Add the chosen element to the result list
        P.append(p)
    
    samples_s1 = self.samples.iloc[Q, :].values.tolist()
    samples_s2 = self.samples.iloc[P, :].values.tolist()
    self.pair_list = list(zip(samples_s1, samples_s2))
    self.lables_s1 = self.labels.loc[Q, 'obj'].values.tolist()
    self.lables_s2 = self.labels.loc[P, 'obj'].values.tolist()
    self.lables_rank = [1 * (self.lables_s1[i] > self.lables_s2[i]) for i in range(len(self.lables_s1))]
    print(self.pair_list[:15], "\n", self.lables_s1[:15], "\n", self.lables_s2[:15], "\n", self.lables_rank[:15])
    
  def create_neighbors_list(self, n): # Create a set of pairs of schedules that are from the same neighborhood
    # Build a subset of random schedules with length n
    S = list(range(len(self.samples)))
    Q = random.choices(S, k=n)
    samples_sub = self.samples.iloc[Q, :].values.tolist()
    labels_sub = self.labels.iloc[Q, 7]
    self.neighbors_list = []
    
    # For each schedule in in the subset choose 2 random intervals i, j and swap 1 patient
    for s in samples_sub:
      i = random.choice(range(len(s)))  # Ensure i is a valid index in s
      j = [index for index, element in enumerate(s) if element > 0 and index != i]
      
      if not j:  # Ensure j is not empty
          continue
      
      j = random.choice(j)  # Choose a random valid index from j
      
      s_pair = s.copy()  # Create a copy of s to modify
      s_pair[i] = s[i] + 1
      s_pair[j] = s[j] - 1
      
      self.neighbors_list.append((s, s_pair))
    print(samples_sub, "\n", self.neighbors_list, "\n", labels_sub)
  
  def calculate_objective(self, schedule, s, d, q):
    s = service_time_with_no_shows(s, q) # Adjust service times distribution for no-shows
    sp = np.array([1], dtype=np.int64) # Set probability of first spillover time being zero to 1
    wt_list = [] # Initialize wt_list for saving all waiting times for all patients in the schedule
    ewt = 0 # Initialize sum of expected waiting times
    for x in schedule: # For each interval -
      if(x == 0): # In case there are no patients,
        wt_temp = [np.array(sp)] # the spillover from the previous interval is recorded,
        wt_list.append([]) # but there are no waiting times.
        sp = [] # Initialize the spillover time distribution 
        sp.append(np.sum(wt_temp[-1][:d+1])) # All the work from the previous interval's spillover that could not be processed will be added to the this interval's spillover.
        sp[1:] = wt_temp[-1][d+1:]
      else: # In case there are patients scheduled,
        wt_temp = [np.array(sp)] # Initialize wt_temp for saving all waiting times for all patients in the interval. The first patient has to wait for the spillover work from the previous period.
        ewt += np.dot(range(len(sp)), sp) # Add waiting time for first patient in interval
        for i in range(x-1): # For each patient
          wt = np.convolve(wt_temp[i], s) # Calculate the waiting time distribution
          wt_temp.append(wt)
          ewt += np.dot(range(len(wt)), wt)
        wt_list.append(wt_temp)
        sp = []
        sp.append(np.sum(np.convolve(wt_temp[-1],s)[:d+1])) # Calculate the spillover
        sp[1:] = np.convolve(wt_temp[-1],s)[d+1:]
    print(f"Schedule: {schedule}, ewt = {ewt}")


with open('./experiments/data.pickle', 'rb') as file:
  sch_data: ScheduleData = pickle.load(file)
  
sch_data.description
sch_data.describe_data()
sch_data.create_pair_list(16000)
sch_data.create_neighbors_list(10)
test_sch = sch_data.neighbors_list[1][0]
sch_data.calculate_objective(test_sch, [0.0, 0.27, 0.28, 0.2, 0.15, 0.1], 3, 0.2)
```

### Flow chart of objective calculation method

```{mermaid}
flowchart TD
    A[Start] --> B[Adjust service times distribution for no-shows]
    B --> C[Set probability of first spillover time being zero to 1]
    C --> D[Initialize wt_list and ewt </br> for saving waiting times distributions and </br>accumulated expected waiting time]
    D --> E[Loop through each interval in schedule]
    
    E --> F{Is x == 0?}
    
    F -->|Yes| G[Record spillover from previous interval]
    G --> H[Append empty list to wt_list]
    H --> I[Initialize spillover time distribution]
    I --> J[Calculate spillover for next interval]
    J --> K[Continue to next interval]

    F -->|No| L[Initialize wt_temp for current interval]
    L --> M[Add spillover from previous interval </br>as waiting time for first patient in current interval]
    M --> N[Loop through each patient in interval]
    
    N --> O[Calculate waiting time distribution for current patient]
    O --> P[Append waiting time distribution to wt_temp]
    P --> Q[Add expected waiting time for current patient to ewt]
    Q --> R[Append wt_temp to wt_list]
    
    R --> S[Initialize spillover time distribution]
    S --> T[Calculate spillover for next interval]
    T --> K[Continue to next interval]
    
    K --> U[Print wt_list]
    U --> V[Print schedule and ewt]
    V --> W[End]

```

## Prepare data

```{python}
# Prepare the dataset
X = []
for pair in sch_data.pair_list:
    X.append(pair[0] + pair[1])

X = np.array(X)
y = np.array(sch_data.lables_rank)

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

## Train and evaluate model

```{mermaid}
flowchart TD
    A[Start] --> B[Initialize StratifiedKFold]
    B --> C[Initialize XGBClassifier]
    C --> D[Set results as empty list]
    D --> E[Loop through each split of cv split]
    E --> F[Get train and test indices]
    F --> G[Split X and y into X_train, X_test, y_train, y_test]
    G --> H[Clone the classifier]
    H --> I[Call fit_and_score function]
    I --> J[Fit the estimator]
    J --> K[Score on training set]
    J --> L[Score on test set]
    K --> M[Return estimator, train_score, test_score]
    L --> M
    M --> N[Append the results]
    N --> E
    E --> O[Loop ends]
    O --> P[Print results]
    P --> Q[End]
```

```{python}
def fit_and_score(estimator, X_train, X_test, y_train, y_test):
    """Fit the estimator on the train set and score it on both sets"""
    estimator.fit(X_train, y_train, eval_set=[(X_test, y_test)])

    train_score = estimator.score(X_train, y_train)
    test_score = estimator.score(X_test, y_test)

    return estimator, train_score, test_score


cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=94)

# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
    tree_method="hist",
    max_depth=6,
    min_child_weight=1,
    gamma=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    learning_rate=0.1,
    n_estimators=100,
    early_stopping_rounds=10
)

results = []

for train_idx, test_idx in cv.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]
    
    est, train_score, test_score = fit_and_score(
        clone(clf), X_train, X_test, y_train, y_test
    )
    results.append((est, train_score, test_score))

# Print results
for i, (est, train_score, test_score) in enumerate(results):
    print(f"Fold {i+1} - Train Score: {train_score:.4f}, Test Score: {test_score:.4f}")
```

## Test

The model seems to be having trouble ranking schedules with close similarity consistently. This could indicate model overfitting. Solutions: create training sets with close pairs or add close pairs to the existing training data set.

```{python}
# Fit the model on the entire dataset
# Initialize the XGBClassifier without early stopping here
clf = xgb.XGBClassifier(
    tree_method="hist",
    max_depth=6,
    min_child_weight=1,
    gamma=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    learning_rate=0.1,
    n_estimators=100
)

clf.fit(X, y)

input_X = [
            ([9, 1, 0, 0, 0, 0, 0], [8, 2, 0, 0, 0, 0, 0]),
            ([8, 2, 0, 0, 0, 0, 0], [9, 1, 0, 0, 0, 0, 0]),
            ([3, 1, 1, 1, 0, 1, 2], [2, 1, 1, 1, 0, 1, 3]),
            ([2, 1, 1, 1, 0, 1, 3], [3, 1, 1, 1, 0, 1, 2]),
            ([3, 1, 1, 1, 0, 1, 2], [9, 1, 0, 0, 0, 0, 0]),
            ([8, 2, 0, 0, 0, 0, 0], [3, 1, 1, 1, 0, 1, 2])
            ]
X_new = []
for pair in input_X:
    X_new.append(pair[0] + pair[1])
    
# Predict the target for new data
y_pred = clf.predict(X_new)

# If you want to get the probability estimates
y_pred_proba = clf.predict_proba(X_new)

print(f"y_pred = {y_pred}, \ny_pred_proba = \n{y_pred_proba}")
```
